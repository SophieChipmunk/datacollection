\chapter{Conclusion / Results}
\label{chap:conclusions}

\section{Introduction}
In the scope of this project I introduced a new Data Container for storing collections of banknote recordings and proposed different automated workflows for generating such NoteSets. I applied these workflows to some real-life use cases that came up in the daily work of the currency adaptation team. In the following section I will present my conclusions and results of this undertaking.

\section{Conclusions on introducing the NoteSet data container}

\begin{itemize}
\item By introducing the Note Set data container a foundational element for the process of Data Collection and Preparation could be established. This project was concurrent to other developments in the Adaptation Data Management and a general shift towards realizing the importance of a flexible, universal annotation that is
	\begin{itemize}
		\item independent of the label/classification of the reader: This is of course of utmost importance: The annotation given by the reader is CDF and firmware dependent and sometimes these very elements are under testing.
		\item independent of the recording tool annotation. This is because a. annotational mistakes could have been made at the time of recording and b. field data generally were not recorded using a dedicated recording tool and are lacking this annotation altogether. 
	\end{itemize}
\item An advantage of the filename-based annotation introduced here is that it is very flexible and comes with little maintenance cost (no additional database for managing annotations is needed, reference NoteSets could be maintained as ASCII files in a simple Git repository). Additionally, the set-based annotation introduces the concept of data equivalence classes, which shifts the focus away from a set-in-stone annotation for each note towards annotation being something more flexible, namely a collection of mappings between a nominal label and a set of elements.
\item Note Sets are small, readable and can be shared easily, even via e-Mail or copy-pasted into a JIRA-Issue. They address the problem of impeded readability that Notelists have.
\item Note Sets lend themselves extremely well to the Microservice Toolchain and can be generated very fast from MDS and MFX. There is even an ongoing discussion of improving this compatibility by introducing dedicated NoteSet endpoints on MDS (cf. Section \ref{section:outlook})
\end{itemize}



\section{Conclusions on the automated NoteSet generation using Jupyter Notebooks}

\begin{itemize}
	\item The python Jupyter Notebooks for automated NoteSet Generation provide a way to quickly and flexibly assemble loadable NoteSets from the MDS API, according to user-specific criteria. While technically this code does not use any high-level algorithms, it has proven to be valuable in a hands-on use case already in the course of this project. Its strength is not algorithmic innovation but rather the fact that it tries to shape a process that previously wasn't consciously seen as a process at all on the one hand, and the automation of actions which manually are very cumbersome and time-intensive on the other.
	\item Finding a way to flatten the note object from the MDS API into a pandas DataFrame opened up the possibility to use standard Python frameworks used in Data Science contexts on the note data. This also allowed to bring statistics into play, something that on the level of data collection had not been done before, e.g. generate a loadable NoteSet of outliers for a particular algorithm result or measured note dimension, using the $\emph{z-Score}$.
	\item By intersecting NoteSets from MDS and MFX the knowledge gap between the two services, namely MDS not knowing about the DataPools directory structure, could be closed.
	\item The proposed process of using the MOVEmSimulator to generate NoteSets constituted an important step for the future Data Collection process because it provides an efficient way for CDF regression testing (cf. Section \ref{section:outlook})
\end{itemize}

\section{Challenges encountered}

\begin{itemize}
	\item Users experienced substantial performance problems when working with automatically generated NoteSets in MCM. The reason for this is the MCM architecture which does not allow the lazy loading of individual notes: Normally, when loading a Notelist in MCM, usually 100 Notes per NIF are loaded. So the NIF to note ratio of a Notelist is about $\frac{1}{100}$. This is because the way users  normally generate Notelists is that they export a selection of complete NIFs into one Notelist. However, the way I introduced NoteSets to the users was in the context of generating tailored data sets for them, selecting dedicated notes based on certain criteria from the entire Data Pool. However, there is usually not an entire NIF with notes satisfying the criteria specified by the user. Taking the example of finding Category 3 (suspected counterfeit notes), there are at most 1 or maybe 2 such notes in a NIF with 100 notes. Therefore a set of 100 Category 3 notes would be expected to originate from a similar amount of NIFs, so the NIF to note ratio in the resulting set would be close to 1. Since Notes within a NIF cannot be loaded lazily in MCM, loading the 100 notes in our hypothetical Category 3 set would mean loading and parsing close to 100 NIFs, as opposed to 1 NIF for loading 100 notes in a standard Notelist. This not only meant a much higher loading time, but also, it seems that MCM is caching unnecessary image data from all the NIFs loaded, which results in high memory usage. \par
It's worth to point out that this problem is of course not a fault in the NoteSet data container -- we would run into the exact same issues if we had stored the 100 Category 3 notes in a Notelist. Rather, this problem has just not occurred before, because there had previously not been any way or process to generate and load tailored data sets which aggregate notes from a large number of individual containers. On the side of application software developers, this problem impressively showed up the necessity to adapt the MCM architecture to allow lazy loading of notes with the help of MDS. 
\item At the beginning I was hopeful to use the algorithmic framework of MCM with the help of an existing MCM Python wrapper library called \emph{mcmp}. My vision was to use these algorithms in a modular way, i.e. just run one chosen algorithm, say the algorithm for Tape detection, over a dataset and then process the data further based on the results. However this proved to be infeasible due to limitation of the Python wrapper library and the complexity of MCM: The wrapper library only contained a limited number of the MCM functionality and using it in Jupyter Notebook turned MCM into a total blackbox. I therefore had to discard this approach and focused on the MOVEmSimulator, which was itself written in Python and could be scripted directly in Jupyter, at the price of not having the individual available in a modular, ``plug-in`` kind of way. 
\end{itemize}

\section{Outlook}
\label{section:outlook}
The following points are currently under discussion for development in a next stage:
\begin{itemize}
	\item Establish the NoteSet data container across the toolchain, specifically in a first step: allow the loading of NoteSets in the MOVEmSimulator. Currently, the MOVEmSimulator allows the loading of NIFs and Notelist files. Allowing the loading of NoteSets would technically not be a very difficult change (this functionality is already implemented in the pynoteset library) and could be an incentive for users to use this data container in their daily work.
	\item Introduce new endpoints on the MDS API which would allow to get notes directly as NoteSets i.e. directly as a list of just Note IDs instead of a list of entire JSON note objects. This would result in smaller HTTP payloads and a smaller number of requests, and thus allow to generate NoteSets even faster.
	\item Version controlled NoteSets in the adaptation team. This is in my opinion a very promising idea. Different reference NoteSets could be managed in a Git Repository (one repository per currency), together with the CDF under development. As the CDF changes between releases, the NoteSets might change as well, a note that was formerly a Category 3 note could now suddenly be in the Category 2 set. These changes could be very easily traceable using Git, since the NoteSet uses an ASCII format. So one could see immediately which adjustment in the CDF caused a note to land in a different set.\par
	As of today, CDFs are not developed using any kind of version control system. One reason for this is that being binary files they don't really lend themselves to be maintained with Git, another one a general hesitance on the side of the adaptation team to introduce Git in their workflows. However, introducing Git for CDF development is intensely discussed at the moment and from this it would only be a small step to introduce NoteSet-based reference data sets as well.
	\item CDF regression tests using NoteSets generated by the MOVEm Simulator. Using the \emph{pynoteset} library, NoteSets can be compared very fast. One area of application of this is the testing of two different CDFs using the same reader firmware. The idea is as follows: The user chooses a reference CDF(\emph{REF}) and a ``device under test`` CDF(\emph{DUT}), as well as a set of NIF files. The NIFs are then processed by the Simulator and the respective NoteSets generated (a procedure that this project proposes and which is set out in one of the Jupyter Notebooks). NoteSets with the same annotation then could be compared quickly and we could answer questions such as: ``Which notes are in the AUD\_5\_a\_1\_1\_CL4\_FF(Tape) \footnote{The annotation reads as follows: genuine AUD (Australian Dollar) 5 a notes, orientation 1, for which the TAPE flag is set} for \emph{REF} and \emph{DUT} respectively and how do these sets differ? ``
\end{itemize}