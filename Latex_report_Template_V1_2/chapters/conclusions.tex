\chapter{Conclusion / Results}
\label{chap:conclusions}

\section{Introduction}
In the scope of this project I introduced a new Data Container for storing collections of banknote recordings and proposed different automated workflows for generating such NoteSets. I applied these workflows to some real-life use cases that came up in the daily work of the currency adaptation team. In the following section I will present my conclusions and results of this undertaking.

\section{Conclusions on introducing the NoteSet data container}

The introduction of the NoteSet data container provided a step towards a reformed data management, which focuses on seeing note records as independent from the NIF file they were recorded in, a concept that has in the past been difficult to communicate to the users. The simplicity of this format provided an intuitive way to communicate this idea to the users, and the NoteSet generation workflows I could demonstrate in Jupyter Notebooks provided a tangible example of this concept's advantages, namely that one can easily generate NoteSets according to different criteria, as well as merge and compare them fast.

On a technical level this data container represents a simplification. Not only is it a lot smaller than the currently used Notelistfile format, but also there is no need to annotate the individual objects within the set. Rather an annotation can be given optionally to the entire set. \par
However, the users experienced substantial performance problems when working with general NoteSets in MCM. The reason for this is the monolithic MCM architecture which does not allow the lazy loading of individual notes: Normally, when loading a Notelist in MCM, usually 100 Notes per NIF are loaded. So the NIF to note ratio of a Notelist is about $\frac{1}/{100}$. This is because the way users generate Notelists is that they export a selection of complete NIFs into one Notelist. However, the way I introduced NoteSets to the users was in the context of generating tailored data sets for them, selecting special Notes based on certain criteria from the entire Data Pool. However, there is usually not an entire NIF with notes satisfying the criteria specified by the user. Taking the example of finding Category 3 (suspected counterfeit notes), there are at most 1 or maybe 2 such notes in a NIF with 100 notes. Therefore a set of 100 Category 3 notes would be expected to originate from a similar amount of NIFs, so the NIF to note ratio in the resulting set would be close to 1. Since Notes within a NIF cannot be loaded lazily in MCM, loading the 100 notes in our hypothetical Category 3 set would mean loading and parsing close to 100 NIFs, as opposed to 1 NIF for loading 100 notes in a standard Notelist. This not only meant a much higher loading time, but also, it seems that MCM is caching unnecessary image data from all the NIFs loaded, which results in high memory usage. \par
It's worth to point out that this problem is of course not a fault in the NoteSet data container -- we would run into the exact same issues if we had stored the 100 Category 3 notes in a Notelist. Rather, this problem has not occurred before, because there had previously not been any way or process to generate tailored data sets which were also loadable in MCM. On the side of application software developers, this problem reinforced the awareness of the necessity to adapt the MCM architecture to allow lazy loading of notes with the help of MDS. \par


\section{Conclusions on Tools and Technologies used}
The motivation for using Jupyter Notebooks was that it would offer a way for quick results independent of the actual toolchain. However, I found that working with Jupyter in a development mindset came with its own set of problems. First, I found it to be somewhat fragile. This was in large part due to the fact that I had to develop my code in the proprietary Cloud, where the MDS and MFX server run. For some reason probably due to limited authorization, I was unable to install any extensions in Jupyterlab. Therefore I always had to switch between Jupyter Notebook and Jupyter Lab to find ways to do certain things for example plot something or use the ipywidgets framework, because something might work in one of either but not in the other. Often, the virtual environment kernels I was using would break in the course of switching between JupyterLab and Jupyter Notebook. Generally I was often left with the feeling of having to redo my entire setup between the days I was working on the Notebooks. I do think that Jupyter Notebooks were they right choice to try out different workflows for the NoteSet generation, also because they lend themselves to demonstration, but it might have been advantageous to implement the functionality in a small library or similar.


\section{Outlook}
The following next steps regarding the integration of the NoteSet data container in the toolchain are currently under discussion
\begin{itemize}
	\item Allow the loading of NoteSets in the MOVEmSimulator. Currently, the MOVEmSimulator allows the loading of NIFs and Notelist files. Allowing the loading of NoteSets would technically not be a very difficult change (this functionality is already implemented in the pynoteset library) and could be an incentive for users to use this data container in their daily work.
	\item Version controlled NoteSets in the adaptation team. This is in my opinion a very promising idea. Different reference NoteSets could be managed in a Git Repository (one repository per currency), together with the CDF under development. As the CDF changes between releases, the NoteSets might change as well, a note that was formerly a Category 3 note could now suddenly be in the Category 2 set. These changes could be very easily traceable using Git, since the NoteSet uses an ASCII format. So one could see immediately which adjustment in the CDF caused a note to land in a different set.\par
	As of today, CDFs are not developed using any kind of version control system. One reason for this is that being binary files they don't really lend themselves to be maintained with Git, another one a general hesitance on the side of the adaptation team to introduce Git in their workflows. However, introducing Git for CDF development is intensely discussed at the moment and from this it would only be a small step to introduce NoteSet-based reference data sets as well. After all a note is never say an ``EUR 5 b Class 3`` as such, but only because there was a particular CDF release once loaded onto the reader which classified the note to be an ``EUR 5 b Class 3``.
\end{itemize}